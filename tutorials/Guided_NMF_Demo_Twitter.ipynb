{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamiehadd/Math189AD-MathematicalDataScienceAndTopicModeling/blob/main/tutorials/Guided_NMF_Demo_Twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8PP0muEJ_bN"
      },
      "source": [
        "# Guided NMF Demo: Twitter\n",
        "This notebook contains a demo for applying the Guided NMF models.  We experiment with the dataset of tweet text from 2016 presidential candidates;\n",
        "> Littman, Justin; Wrubel, Laura; Kerchner, Daniel, 2016, \"2016 United States Presidential Election Tweet Ids\", https://doi.org/10.7910/DVN/PDI7IN, Harvard Dataverse, V3.\n",
        "\n",
        "This dataset has been provided for you in \"all_tweets_avg.npy\" and \"all_tweets_words.npy.\"  Keep these files private as they have been extracted via the Twitter API by a single user account and are not for distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHpmXIx5KJvK"
      },
      "source": [
        "### Activity\n",
        "We'll be applying NMF and Guided NMF to a dataset consisting of tweets from 2016 presidential candidates and investigating the results of these models!\n",
        "- Run the NMF and Guided NMF models in the notebook.\n",
        "- Interpret the results.\n",
        "- Design your own experiments (consider different topics and words for guidance)!\n",
        "- Report back with interesting findings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24M5die2Kt5q"
      },
      "source": [
        "### Run first: Install and import calls, and function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFzuIvzXwQ3j"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install ssnmf\n",
        "!pip install scipy\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import ssnmf\n",
        "from ssnmf import SSNMF\n",
        "import scipy\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijqTX3waKwzf"
      },
      "outputs": [],
      "source": [
        "def d_to_v(d, verbose=True):\n",
        "    \"\"\"\n",
        "    Given dictionary d of form {word: weight}, created GT topic vector v. See writeup for details.\n",
        "    \"\"\"\n",
        "    l = list(idx_to_word)\n",
        "    v = np.zeros(idx_to_word.shape[0])\n",
        "\n",
        "    for key in d.keys():\n",
        "        i = l.index(key)\n",
        "        if(i < 0):\n",
        "            print(\"Could not find word '\" + key + \"' in list of words!\")\n",
        "        else:\n",
        "            v[i] = d[key]\n",
        "\n",
        "    return v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQvOPv-aK5Yg"
      },
      "source": [
        "### Data Preprocessing\n",
        "In these blocks, we load and format the tweet dataset, and create properly formatted seed topics in Y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3a_CD1bLTTD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c52zZySLfXG"
      },
      "outputs": [],
      "source": [
        "cd '/content/drive/Shareddrives/Math 189AD FA22: Datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv3gupVyK1bZ"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "X = np.load(\"all_tweets_avg.npy\", allow_pickle=True)\n",
        "idx_to_word = np.load(\"all_tweets_words.npy\", allow_pickle=True)\n",
        "X = X.item()\n",
        "X = scipy.sparse.csr_matrix.toarray(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcfxDeg0LFaX"
      },
      "outputs": [],
      "source": [
        "# Create seed topics and Y matrix\n",
        "obamacare_word = {\"obamacare\": 1}\n",
        "economy_words = {\"economy\": 1}\n",
        "\n",
        "gt_topic_words = [obamacare_word, economy_words]\n",
        "gt_topic_vectors= [d_to_v(x) for x in gt_topic_words]\n",
        "\n",
        "Y = np.stack(gt_topic_vectors).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxZ4ZRQih-dM"
      },
      "source": [
        "### Experiment 1: NMF on Twitter Data\n",
        "In this experiment, we first train a Frobenius-norm NMF model on the tweets dataset (with no supervision or guidance).  We extract the five top keywords represented in each topic (these are the five highest values in each row of S)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfF_SKEzh--W"
      },
      "outputs": [],
      "source": [
        "#seed the random matrix initialization for reproducable results\n",
        "np.random.seed(1)\n",
        "r = 8\n",
        "\n",
        "#intialize and train the model\n",
        "model = SSNMF(X.T,r)\n",
        "N=200\n",
        "model.mult(numiters = N)\n",
        "\n",
        "#access the factor matrices\n",
        "S = model.A.T\n",
        "A = model.S.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L1tzVnKiBan"
      },
      "outputs": [],
      "source": [
        "#collect and print the top keywords for each topic\n",
        "keywords = np.empty((7,r), dtype=object)\n",
        "\n",
        "for i in range(keywords.shape[1]):\n",
        "    keywords[0,i] = \"Topic \" + str(i+1)\n",
        "    keywords[1,i] = \"-------\"\n",
        "\n",
        "for i in range(A.shape[1]):\n",
        "    col = A[:,i]\n",
        "    top = col.argsort()\n",
        "    top = top[-5:][::-1]\n",
        "\n",
        "    keywords[2:,i] = idx_to_word[top]\n",
        "\n",
        "\n",
        "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
        "for row in keywords:\n",
        "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Y1VOYJi02Q"
      },
      "source": [
        "### Experiment 2: Guided NMF on Twitter Data\n",
        "In this experiment, we train a Frobenius-norm Guided NMF model on the tweets dataset with guidance towards the words \"obamacare\" and \"economy\".  We extract the five top keywords represented in each topic (these are the five highest values in each row of S)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlhv7L-9it13"
      },
      "outputs": [],
      "source": [
        "#seed the random matrix initialization for reproducable results\n",
        "np.random.seed(1)\n",
        "\n",
        "#intialize and train the model\n",
        "model_3 = SSNMF(X.T,r,Y=Y.T,lam=0.5,modelNum=3)\n",
        "N=200\n",
        "model_3.mult(numiters = N)\n",
        "\n",
        "#access the factor matrices\n",
        "S = model_3.A.T\n",
        "A = model_3.S.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZCHt3DAi7mX"
      },
      "outputs": [],
      "source": [
        "#collect and print the top keywords for each topic\n",
        "keywords = np.empty((7,r), dtype=object)\n",
        "\n",
        "for i in range(keywords.shape[1]):\n",
        "    keywords[0,i] = \"Topic \" + str(i+1)\n",
        "    keywords[1,i] = \"-------\"\n",
        "\n",
        "for i in range(A.shape[1]):\n",
        "    col = A[:,i]\n",
        "    top = col.argsort()\n",
        "    top = top[-5:][::-1]\n",
        "\n",
        "    keywords[2:,i] = idx_to_word[top]\n",
        "\n",
        "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
        "for row in keywords:\n",
        "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8zh5bwS54yIm2/YEI21KJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}