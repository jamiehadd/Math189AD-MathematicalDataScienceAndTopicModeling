{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOly7K74Blg11NNoFCHfLOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamiehadd/Math189AD-MathematicalDataScienceAndTopicModeling/blob/main/tutorials/Nonnegative_Matrix_Factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Math 189: Nonnegative Matrix Factorization (Our Lens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this notebook, we'll explore the application of nonnegative matrix factorization (NMF) on a toy dataset."
      ],
      "metadata": {
        "id": "nR8ivvgyBLX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Activity**\n",
        "\n",
        "In this notebook, we'll explore NMF applied to a toy dataset.  You'll then have the opportunity to explore this model on a new data set!  You should try to select a dataset where you believe the outputs from these models will be interpretable and visualizable!"
      ],
      "metadata": {
        "id": "fHTOC33fBYqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tasks\n",
        "\n",
        "* Divide into small groups (2 or 3 people).\n",
        "* Explore the code below applying NMF to a toy dataset!\n",
        "* Identify the dataset you want to explore.\n",
        "* Think about how this data is formatted (is it a matrix? nonnegative?) and hypothesize about what the outcome of NMF will be!\n",
        "* Run your NMF model.\n",
        "* Try to interpret the results.\n",
        "* Report back with interesting findings!"
      ],
      "metadata": {
        "id": "s7t_GXvRBuNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXYERP6tBEI_",
        "outputId": "74205563-b290-4389-c444-a7651edf2f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're exploring the [20 Newsgroups](https://scikit-learn.org/stable/datasets/real_world.html?highlight=newsgroups#the-20-newsgroups-text-dataset) data set, which is a collection of approximately 20,000 newsgroup (think \"email chatroom\") documents. The data set consists of six groups (\"comp\", \"misc\", \"rec\", \"sci\", \"soc\", and \"talk\") partitioned roughly according to subjects, with a total of 20 subgroups, and is commonly used\n",
        "as an experimental benchmark for document classification\n",
        "and clustering.\n",
        "\n",
        "In this notebook, we load only 10 subgroups from the five groups \"comp\", \"misc\", \"rec\", \"sci\", and \"talk\"; this list of group and subgroups is called `categories` below.  We remove stopwords and some other often used words, remove numbers, and use a common document data transformation called \"term-frequency inverse document-frequence (tf-idf)\" to construct our data matrix."
      ],
      "metadata": {
        "id": "hPTeAeBLKsri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remove = ('headers','footers','quotes')\n",
        "stopwords_list = stopwords.words('english')\n",
        "stopwords_list.extend(['thanks','edu','also','would','one','could','please','really','many','anyone','good','right','get','even','want','must','something','well','much','still','said','stay','away','first','looking','things','try','take','look','make','may','include','thing','like','two','or','etc','phone','oh','email'])\n",
        "\n",
        "categories = [\n",
        " 'comp.graphics',\n",
        " 'comp.sys.mac.hardware',\n",
        " 'misc.forsale',\n",
        " 'rec.motorcycles',\n",
        " 'rec.sport.baseball',\n",
        " 'sci.med',\n",
        " 'sci.space',\n",
        " 'talk.politics.guns',\n",
        " 'talk.politics.mideast',\n",
        " 'talk.religion.misc'\n",
        " ]\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
        "\n",
        "# remove numbers\n",
        "data_cleaned = [re.sub(r'\\d+','', file) for file in newsgroups_train.data]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords_list)\n",
        "vectors = vectorizer.fit_transform(data_cleaned).transpose()\n",
        "idx_to_word = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "X = vectors"
      ],
      "metadata": {
        "id": "wJp-hANT1pEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll apply NMF with rank k.  Note that scikit-learn, one of the most widely-used Python tools for machine learning, has you declare an NMF model before actually performing the model training on the data X and accessing the two factor matrices W and H."
      ],
      "metadata": {
        "id": "ioSuNEMqOCIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 10\n",
        "\n",
        "model = NMF(n_components=k, init='random', random_state=0,max_iter = 1000)  #learn the NMF model\n",
        "W = model.fit_transform(X)                                              #access the NMF factor matrices\n",
        "H = model.components_"
      ],
      "metadata": {
        "id": "BHJhzHg-3EYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we print out the top 10 keywords of each topic below!  Investigate these topics and see if you can identify which group and subgroup to which they most closely relate."
      ],
      "metadata": {
        "id": "QG8d-BKyPIRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_keywords = 10\n",
        "\n",
        "keywords = np.empty((num_keywords+2,k), dtype=object)\n",
        "\n",
        "for i in range(keywords.shape[1]):\n",
        "    keywords[0,i] = \"Topic \" + str(i+1)\n",
        "    keywords[1,i] = \"-------\"\n",
        "\n",
        "for i in range(W.shape[1]):\n",
        "    col = W[:,i]\n",
        "    top = col.argsort()\n",
        "    top = top[-10:][::-1]\n",
        "\n",
        "    keywords[2:,i] = idx_to_word[top]\n",
        "\n",
        "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
        "for row in keywords:\n",
        "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITe1XwnG3-o2",
        "outputId": "964f6a25-4c04-4d6c-cf25-9a3832ad0c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1  Topic 2   Topic 3     Topic 4   Topic 5  Topic 6  Topic 7   Topic 8   Topic 9     Topic 10    \n",
            "-------  -------   -------     -------   -------  -------  -------   -------   -------     -------     \n",
            "people   year      sale        israel    card     space    graphics  drive     armenian    geb         \n",
            "think    game      shipping    israeli   mac      nasa     files     hard      armenians   dsl         \n",
            "know     team      offer       jews      monitor  shuttle  file      scsi      turkish     chastity    \n",
            "gun      games     new         arab      video    launch   image     disk      genocide    njxp        \n",
            "say      runs      condition   arabs     mb       orbit    know      internal  armenia     cadre       \n",
            "time     last      asking      lebanese  apple    moon     program   drives    turkey      skepticism  \n",
            "see      pitching  price       lebanon   simms    lunar    software  floppy    turks       pitt        \n",
            "us       baseball  sell        peace     color    earth    mail      cd        people      shameful    \n",
            "god      hit       best        adam      lc       station  ftp       meg       soviet      intellect   \n",
            "guns     win       interested  jewish    bit      sci      windows   mb        government  surrender   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What topics make sense?  Any confusing ones?  You likely have a topic with the words \"chastity\", \"skepticism\", \"intellect\", and \"cadre\".  What is up with this topic?  Try to do a little internet sleuthing!  It may surprise you where this common topic came from."
      ],
      "metadata": {
        "id": "NFZA-kxCPvmI"
      }
    }
  ]
}