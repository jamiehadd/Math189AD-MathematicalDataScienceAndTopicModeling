# MATH 189: Mathematical Data Science & Topic Modeling

<p align="center">
<img width="600" src="https://raw.githubusercontent.com/jvendrow/fnnls/master/fnnls_logo.png?raw=true" alt="logo">
</p>

Prof. Jamie Haddock, <jhaddock@g.hmc.edu>

In this course, students will learn about common mathematical representations of data, the mathematical foundations of matrix factorization and tensor decomposition, and their application to many tasks in machine learning and data science.  These decomposition techniques are integral tools in studying large-scale and multi-modal data and form the basis for many approaches to the topic modeling, dimension reduction, and clustering tasks.  Potential topics include PCA, nonnegative matrix factorization, higher-order SVD, nonnegative tensor decompositions, K-means clustering, optimization techniques for these models, and applications in machine learning, data science, signal processing, and network science.


## AIMS FOR THE COURSE

In this course, we will engage with current mathematical and data scientific research.  It has been designed to strengthen your skills in reading and analyzing research papers, and writing and presenting your own research.


## READING ASSIGNMENTS

Reading assignments are the primary way that you will engage with course content outside of lecture.  These readings serve several important purposes, including to introduce you to state-of-the-art techniques in the field and to develop competency in reading academic papers.

Reading will be assigned weekly and each reading has two components.

The first part is the active reading of the assigned article. You will access the assigned reading via Google Classroom, and then you will engage in active reading of the article via annotations and discussions in Google.

The second part is a short-answer reflection that will be accessed via Gradescope. The overview focuses on big-picture concepts and mathematical ideas from the article and should be completed after you have finished the active reading. You will submit this part directly to Gradescope.

Using Gradescope: If you are registered for this course, you should have already been added to the Gradescope class page. Contact your instructor if you are having problems with access. Gradescope has several tutorial resources, e.g., [Gradescope video tutorials](https://www.gradescope.com/get_started#student-submission).  


## TENTATIVE SCHEDULE

| Week |	Date | Topic |	Assigned Readings | Assignments Due |
| --- | --- | --- | --- | --- |
| 1 |	M | Syllabus, Class Norms, Ice-breakers | | |	 	 

W Aug 31

Data and Data Science 	
Baker, Matthew. "How to Read a Research Paper." Notices of the American Mathematical Society 67.5 (2020): 660-662.

Higham, Nicholas J. "How to Read and Understand a Paper." (2015): 903-906.

Optional: Kolda, Tamara. "Mathematics: The Tao of Data Science." Harvard Data Science Review (2020).

Optional: Breiman, Leo. "Statistical modeling: The two cultures (with comments and a rejoinder by the author)." Statistical science 16.3 (2001): 199-231.

Due: W Sep 7 before class (Reflection 1)


2	M Sep 5	No Class: Labor Day	 	 
 	W Sep 7	Linear Algebra, Optimization, and Probability Tools
Lee, Daniel D., and H. Sebastian Seung. "Learning the parts of objects by non-negative matrix factorization." Nature 401.6755 (1999): 788-791.

Due: T Sep 13 by end of day (Reflection 2)

Reflection 1
3
M Sep 12

Our lens: Nonnegative Matrix Factorization



 	W Sep 14	Discussion and Tutorial
Chapter 1 of Gillis, Nicolas. Nonnegative Matrix Factorization. Society for Industrial and Applied Mathematics, 2020.

Due: T Sep 20 by end of day (Reflection 3)

Reflection 2 + Rubric

(see rubric guide)

4
M Sep 19

Dimensionality Reduction and Clustering	 	 

W Sep 21

Discussion and Tutorial
Kolda, Tamara G., and Brett W. Bader. "Tensor decompositions and applications." SIAM review 51.3 (2009): 455-500.

Rabanser, Stephan, Oleksandr Shchur, and Stephan GÃ¼nnemann. "Introduction to tensor decompositions and their applications in machine learning." arXiv preprint arXiv:1711.10781 (2017).

Due: T Sep 27 by end of day (Reflection 4)

Reflection 3
5
M Sep 26

Tensor Decomposition Models




W Sep 28

No Class: Tutorial at Home
Lee, D. D., and H. S. Seung. "Algorithms for Non-Negative Matrix Factorization. NIPS (2000)." Google Scholar: 556-562.

Due: T Oct 4 by end of day (Reflection 5)

Reflection 4
6
M Oct 3

Training NMF models	 	 

W Oct 5

Discussion and Tutorial	 	Reflection 5
7
M Oct 10

Overview of NMF Variants	 	 

W Oct 12

Team Building	 	Topic brainstorm
8
M Oct 17

No Class: Fall Break	 	 

W Oct 19

Statistical Foundations of NMF	 	 
9
M Oct 24

Group pitch development	 	 

W Oct 26

Topic pitches, Writing Center Visit, and Mid-Semester Evaluations
Lee, Hyekyoung, Jiho Yoo, and Seungjin Choi. "Semi-supervised nonnegative matrix factorization." IEEE Signal Processing Letters 17.1 (2009): 4-7.

Haddock, Jamie, et al. "Semi-supervised NMF Models for Topic Modeling in Learning Tasks." arXiv preprint arXiv:2010.07956 (2020).

Due: T Nov 1 by end of day (Reflection 6)

Group pitch
 	F Oct 28	 	 	Group abstract
10
M Oct 31

Supervised NMF Variants	 	 

W Nov 2

Discussion and Tutorial
Kuang, Da, Sangwoon Yun, and Haesun Park. "SymNMF: nonnegative low-rank approximation of a similarity matrix for graph clustering." Journal of Global Optimization 62.3 (2015): 545-574.

Due: T Nov 8 by end of day (Reflection 7)

Reflection 6
11
M Nov 7

Community Detection with NMF	 	Midsemester reflection

W Nov 9

Discussion and Tutorial/Group Project Work
De Handschutter, Pierre, Nicolas Gillis, and Xavier Siebert. "Deep matrix factorizations." arXiv preprint arXiv:2010.00380 (2020).

Due: T Nov 15 by end of day (Reflection 8)

Reflection 7
12
M Nov 14

Hierarchical NMF	 	 

W Nov 16

Discussion and Tutorial/Group Project Work
Koren, Yehuda, Robert Bell, and Chris Volinsky. "Matrix factorization techniques for recommender systems." Computer 42.8 (2009): 30-37.

Due: T Nov 22 by end of day (Reflection 9)

Reflection 8
13
M Nov 21

NMF Applications: Recommender Systems and more	 	Reflection 9

W Nov 23

No Class: Thanksgiving Break	 	 
14
M Nov 28

Convex NMF and Archetypal Analysis/Group Project Work	 	 

W Nov 30

No Class	 	 
15	M Dec 5	Group Project Presentations	 	Group extended summary
 	W Dec 7	Group Project Presentations	 	 
Finals
W Dec 14

 	 	Group paper

F Dec 16

 	 	Final reflection
