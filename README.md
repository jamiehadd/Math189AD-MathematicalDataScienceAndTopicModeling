# MATH 189: Mathematical Data Science & Topic Modeling

<p align="center">
<img width="600" src="https://raw.githubusercontent.com/jvendrow/fnnls/master/fnnls_logo.png?raw=true" alt="logo">
</p>

Prof. Jamie Haddock, <jhaddock@g.hmc.edu>

In this course, students will learn about common mathematical representations of data, the mathematical foundations of matrix factorization and tensor decomposition, and their application to many tasks in machine learning and data science.  These decomposition techniques are integral tools in studying large-scale and multi-modal data and form the basis for many approaches to the topic modeling, dimension reduction, and clustering tasks.  Potential topics include PCA, nonnegative matrix factorization, higher-order SVD, nonnegative tensor decompositions, K-means clustering, optimization techniques for these models, and applications in machine learning, data science, signal processing, and network science.


## AIMS FOR THE COURSE

In this course, we will engage with current mathematical and data scientific research.  It has been designed to strengthen your skills in reading and analyzing research papers, and writing and presenting your own research.


## READING ASSIGNMENTS

Reading assignments are the primary way that you will engage with course content outside of lecture.  These readings serve several important purposes, including to introduce you to state-of-the-art techniques in the field and to develop competency in reading academic papers.

Reading will be assigned weekly and each reading has two components.

The first part is the active reading of the assigned article. You will access the assigned reading via Google Classroom, and then you will engage in active reading of the article via annotations and discussions in Google.

The second part is a short-answer reflection that will be accessed via Gradescope. The overview focuses on big-picture concepts and mathematical ideas from the article and should be completed after you have finished the active reading. You will submit this part directly to Gradescope.

Using Gradescope: If you are registered for this course, you should have already been added to the Gradescope class page. Contact your instructor if you are having problems with access. Gradescope has several tutorial resources, e.g., [Gradescope video tutorials](https://www.gradescope.com/get_started#student-submission).  


## TENTATIVE SCHEDULE

| Week |	Date | Topic |	Assigned Readings | Assignments Due |
| --- | --- | --- | --- | --- |
| 1 |	M | Syllabus, Class Norms, Ice-breakers | | |	 	 
| | W | Data and Data Science | Baker, Matthew. "How to Read a Research Paper." Notices of the American Mathematical Society 67.5 (2020): 660-662. <br> Higham, Nicholas J. "How to Read and Understand a Paper." (2015): 903-906. <br> Optional: Kolda, Tamara. "Mathematics: The Tao of Data Science." Harvard Data Science Review (2020). <br> Optional: Breiman, Leo. "Statistical modeling: The two cultures (with comments and a rejoinder by the author)." Statistical science 16.3 (2001): 199-231.<br> **Due:** W Sep 7 before class (Reflection 1) | |
| 2	| M |	No Class | | |	 	 
| | W |	Linear Algebra, Optimization, and Probability Tools | Lee, Daniel D., and H. Sebastian Seung. "Learning the parts of objects by non-negative matrix factorization." Nature 401.6755 (1999): 788-791.<br> **Due:** T Sep 13 by end of day (Reflection 2)| Reflection 1 |
| 3 | M | Our lens: Nonnegative Matrix Factorization | | |
| | W | Discussion and Tutorial | Chapter 1 of Gillis, Nicolas. Nonnegative Matrix Factorization. Society for Industrial and Applied Mathematics, 2020. <br> **Due:** T Sep 20 by end of day (Reflection 3) | Reflection 2 + Rubric (see rubric guide)|
| 4 | M | Dimensionality Reduction and Clustering | | |	 
| | W | Discussion and Tutorial| Kolda, Tamara G., and Brett W. Bader. "Tensor decompositions and applications." SIAM review 51.3 (2009): 455-500. <br> Rabanser, Stephan, Oleksandr Shchur, and Stephan GÃ¼nnemann. "Introduction to tensor decompositions and their applications in machine learning." arXiv preprint arXiv:1711.10781 (2017). <br> **Due:** T Sep 27 by end of day (Reflection 4) | Reflection 3 |
| 5 | M | Tensor Decomposition Models | | |
| | W | Discussion and Tutorial | Lee, D. D., and H. S. Seung. "Algorithms for Non-Negative Matrix Factorization. NIPS (2000)." Google Scholar: 556-562. <br> **Due:** T Oct 4 by end of day (Reflection 5) | Reflection 4 |
| 6 | M | Training NMF models	| | |  	 
| | W | Discussion and Tutorial | |	Reflection 5 |
| 7 | M | Overview of NMF Variants | | | 	 
| | W | Team Building | |	Topic brainstorm |
| 8 | M | No Class | | |	 	 
| | W | Statistical Foundations of NMF | | |
| 9 | M | Group pitch development | | |
| | W | Topic pitches, Writing Center Visit, and Mid-Semester Evaluations | Lee, Hyekyoung, Jiho Yoo, and Seungjin Choi. "Semi-supervised nonnegative matrix factorization." IEEE Signal Processing Letters 17.1 (2009): 4-7. <br> Haddock, Jamie, et al. "Semi-supervised NMF Models for Topic Modeling in Learning Tasks." arXiv preprint arXiv:2010.07956 (2020). <br> **Due:** T Nov 1 by end of day (Reflection 6) | Group pitch |
| | F | | | Group abstract |
| 10 | M | Supervised NMF Variants | | | 	 
| | W | Discussion and Tutorial | Kuang, Da, Sangwoon Yun, and Haesun Park. "SymNMF: nonnegative low-rank approximation of a similarity matrix for graph clustering." Journal of Global Optimization 62.3 (2015): 545-574. <br> **Due:**  T Nov 8 by end of day (Reflection 7) | Reflection 6 |
| 11 | M | Community Detection with NMF | |	Midsemester reflection |
| | W Nov | Discussion and Tutorial | De Handschutter, Pierre, Nicolas Gillis, and Xavier Siebert. "Deep matrix factorizations." arXiv preprint arXiv:2010.00380 (2020).<br> **Due:** T Nov 15 by end of day (Reflection 8) | Reflection 7 |
| 12 | M | Hierarchical NMF | | |
| | W | Discussion and Tutorial | Koren, Yehuda, Robert Bell, and Chris Volinsky. "Matrix factorization techniques for recommender systems." Computer 42.8 (2009): 30-37.<br> **Due:** T Nov 22 by end of day (Reflection 9) | Reflection 8 |
| 13 | M | NMF Applications: Recommender Systems and more | | Reflection 9 |
| | W | No Class | | |  	 
| 14 | M | Convex NMF and Archetypal Analysis | | |	 	 
| | W | No Class | | |
| 15 | M | Group Project Presentations | | Group extended summary |
| | W | Group Project Presentations | | |	 
| Finals | W | | | Group paper |
| | F | | | Final reflection |
